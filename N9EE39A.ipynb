{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Travaux Pratiques - N9EE39A Edge Computing\n\n**Contact: Adrien THIRION ([email](adrien.thirion@nanomade.com))**  \n\n**Créé en Octobre 2023**\n\n\n\nL'objectif de ces séances de travaux pratiques est de vous familiariser avec le métier de Data Scientists, plus particulièrement dans un environnement contraint (système embarqué). Celui-ci a été pensé pour développer une vue d'ensemble de toutes les étapes nécessaires lors de la création d'un modèle, jusqu'à ce que celui-ci soit embarqué.\n\n\n\nComme tout bon data scientist, l'utilisation de fonction existante sur internet est **vitale** !! En effet, l'intelligence artificielle est très présent de nos jours, donc si vous avez un problème, il est presque assuré que quelqu'un ait déjà eu le même !\n\n\n\nLe TP va se porter sur un sujet concret: la reconnaissance vocal. Ce sujet rentre dans le thème du Traitement automatique du langage naturel ou NLP [[1]](https://en.wikipedia.org/wiki/Natural_language_processing)) où la demande en IA embarqué est très recherchée (ex. enceinte connecté, smartphone, smartwatches, ..). Pour cela, vous allez vous baser sur une base de données existante se trouvant Kaggle: the TensorFlow Speech Recognition Challenge. Kaggle est un site de competition permettant de récompenser les meilleurs modèles avec des prix décernés aux meilleurs modèles. Cette compétition a été organisée par Google, avec plus de 25 000$ à gagner. Certaines peuvent même dépasser le million de dollard (ex. Netflix Price) donc si vous avez soif d'argent ou que le l'IA vous plaît, allez y jeter un coup d'oeil !\n\n\n\nDans ce projet, vous allez essayer de classer correctement les 12 labels présents dans cette base de donnée via un modèle de convolution 1D ou récursif que vous aurez optimisé. Puis, vous devrez visualiser la variation des performances de ce modèle en fonction de son allégement (dans une volonté de l'embarquer).\n\n\n\nLe Rapport devra être fait sur ce jupyter notebook, en Markdown (comme le texte que vous êtes en train de lire).\n\n\n\nCe projet a pour but d'évaluer votre esprit critique, votre analyse d'un problème et votre regard critique sur vos performances. Pour cela, l'entraide est encouragée mais en aucun cas le plagiat. Merci de respecter cela (promis c'est pour votre bien). Expliquez bien votre démarche et la raison de vos choix !!\n\n\n\nLe projet sera découpé en 5 TPs de 4h. Un guide de progession sera affiché sur chaque partie pour connaître votre avancement.\n\n\n\n\n\nCe projet va être découpé en plusieurs parties:\n\n\n\n\n\n1. L'Analyse de la base de donnée.\n\n1. L'état de l'art.\n\n1. Le Preprocessing.\n\n1. L'apprentissage du modèle.\n\n1. Les résultats et discussions.\n\n1. L'allégement du modèle.\n\n1. La conclusion.","metadata":{"id":"1bd3b382"}},{"cell_type":"markdown","source":"## Analyse de la base de donnée\n\n\n\n\n\nLa première étape est de télecharger et d'analyser la base de donnée. Pour cela rendez vous sur le site de la compétition:  \n\nhttps://www.kaggle.com/competitions/tensorflow-speech-recognition-challenge/overview\n\n\n\nPensez à bien regarder la compétition en détail, cela pourra vous être très utile (comme par exemple trouver du code ou des articles).\n\n\n\n&nbsp;\n\n\n\n<font color=\"Darkred\"> Progression du TP après cette partie (environ 2h): </font>  ","metadata":{"id":"1bb136b5"}},{"cell_type":"markdown","source":"### Information sur la base de donnée\n\n<font color=\" Darkblue\"> **Tips:** Parlez de tous ce que vous savez des données (quantité d'instances, les labels, la taille d'une time series, sa fréquence d'echantillonage, ...). </font>\n\n\n\nFréquence d'échantillonnage : 16kHz\n\nQuantité d'instances : 64727\n\nNombre de labels : 12 (unkown étant composés de plusieurs labels non reconnus)\n\nTaille d'une time series : 1 seconde (16000 points)\n\n\n","metadata":{"id":"2b969919"}},{"cell_type":"markdown","source":"### Visualitation d'une donnée et analyse critique\n\n<font color=\" Darkblue\"> **Tips:** Faites un subplot de plusieurs labels différents pour voir visuellement les différences. </font>\n\n\n\n> **Ecrire votre texte ici.**","metadata":{"id":"990a7026"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport IPython.display as ipd\n\nfrom scipy.io import wavfile\n\n\n\nfrom google.colab import drive # Pour google colab\n\ndrive.mount('/content/drive')  # Pour google colab\n\n\n\n# Ajouter ce dossier dans votre drive: https://drive.google.com/drive/folders/1AAiaDTWJzvS6NaZXE_dfJ603QWhhcl0R?usp=sharing","metadata":{"id":"fba49826","outputId":"2d81a7e7-c7ed-4b53-b6f3-7368dc811ca9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir data\n\n!cp /content/drive/MyDrive/tensorflow-speech-recognition-challenge/* /content/data/  # Pour google colab","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#subplot sur plusieurs classes :\n\n\n\nsample_rate, samples = wavfile.read('/content/data/train/audio/yes/0a7c2a8d_nohash_0.wav')\n\nsample_rate2, samples2 = wavfile.read('/content/data/train/audio/no/0a7c2a8d_nohash_0.wav')\n\nplt.subplot(1, 2, 1)\n\nplt.plot(samples)\n\nplt.title('yes')\n\nplt.subplot(1, 2, 2)\n\nplt.plot(samples2)\n\nplt.title('no')\n\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Exporter une donnée\n\n# sample_rate, time_series = wavfile.read('/content/data/train/audio/bird/00b01445_nohash_0.wav')\n\n\n\n# Ecouter la donnée\n\n# ipd.Audio(time_series, rate=sample_rate)","metadata":{"id":"9CJBWg28M2el","outputId":"57ff6a13-da03-44b5-c935-bc453dd747d5"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Stockage des données\n\n <font color=\"red\"> **ATTENTION:** Respectez l'ordre des labels: 0 = yes, 1 = no, 2 = up, 3 = down, 4 = left, 5 = right, 6 = on, 7 = off, 8 = stop, 9 = go, 10 = silence, 11 = unknown </font>\n\n\n\n<font color=\" Darkblue\"> **Tips:** Réduisez la taille des données d'entrées afin d'éviter la saturation de la mémoire </font>","metadata":{"id":"09e76b10"}},{"cell_type":"code","source":"import os\n\n\n\ndef import_data():\n\n    all_waves, all_labels = [], []\n\n\n\n    # TO DO !!\n\n\n\n    return np.array(all_waves), np.array(all_labels)\n\n\n\nall_waves, all_labels = import_data()","metadata":{"id":"51e542a8"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## \nEtat de l'art\n\n\n\nEtape importante qui suit: faire un état de l'art. Que cela soit pour innover, ou pour trouver une solution existante pertinente, faire un état de l'art scientifique est essentiel. Ici, vous devez chercher les articles liés à ce projet. Il faut pour cela remplir le tableau et bien marquer leurs références en dessous. De plus, un texte synthétique vous sera demandé pour expliquer selon vous, quels papiers sont les plus pertinants pour la suite de ce projet.\n\n\n\nAttention: une analyse critique est nécessaire sur ces papiers (certain papiers peuvent avoir des biais cachés).\n\n\n\n<font color=\"orange\"> **Note anti-plagiat:** Au moins 2 références devraient être différente des autres binômes. </font>\n\n\n\n&nbsp;\n\n\n\n\n\n<font color=\"Darkred\"> Progression du TP après cette partie (environ 2h):\n\n\n\n&nbsp;\n\n\n\n> **Ecrire votre texte ici.**\n\n\n\n| References | Preprocessing | Modèle |  Solution Embarquée ? | Dataset utilisé | Performances |\n\n| :---------------- | :------: | :----: | :----: | :----: | :----: |\n\n| MatchboxNet 2020 1D CNN | pas vue |  MatchboxNet | Non (77k param)| Google Speech Commands v1 | 97% | \nlink :  https://arxiv.org/pdf/2004.08531v2 / 5/5\n\n| TRAINING WITH LIMITED DATA | ?  |  pre-trained ”Embedding+Head” Model | oui| speech commands |  97.4% | \nlink :  https://arxiv.org/pdf/2002.01322 / 3/5\n\n| attention model 2018 | pas vue |   Attention RNN | Non (77k param)| Google Speech Commands dataset V1 |  94.1% | \nlink :  https://arxiv.org/pdf/2004.08531v2  / \n\n\n\n| toto et al. [1]       |  -  | - | - | - | - |\n\n\n\n#### Références:\n\n- [1]: toto et al., .....","metadata":{"id":"59d4b38f"}},{"cell_type":"markdown","source":"## Preprocessing\n\n\n\nC'est la partie la plus importante du projet !! Même le modèle le plus performant de la terre ne pourra pas être précis sans des données d'entrées propres. De plus, il est important de réduire la quantité de données d'entrée (Décimation) afin de ne pas avoir un modèle trop lourd.\n\n\n\n<font color=\" Darkblue\"> **Tips:** Commencez par un preprocessing simple, et améliorez le lorsque les modèles seront en cours d'apprentissage. </font>\n\n\n\nVoici quelques sources qui pourront vous être utile pour faire votre code, en plus de l'état de l'art précedemment fait:\n\n- https://medium.com/enjoy-algorithm/pre-processing-of-time-series-data-c50f8a3e7a98\n\n- https://monkeylearn.com/blog/data-preprocessing/\n\n- https://machinelearningmastery.com/machine-learning-data-transforms-for-time-series-forecasting/\n\n- https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html (pour les plus expérimenté d'entre vous)\n\n\n\n&nbsp;\n\n\n\n<font color=\" Darkred\"> Progression du TP après cette partie (environ 3h): </font>  \n\n![56%](https://progress-bar.dev/56)\n","metadata":{"id":"e569e15d"}},{"cell_type":"markdown","source":"### Zone d'expérimentation\n\n\n\nIci vous êtes libre d'essayer des choses, les visualiser, avoir un regard critique sur la solution que vous décidez de prendre. Utilisez autant de cases de codes et de textes.","metadata":{"id":"266b5a91"}},{"cell_type":"markdown","source":"### Fonction de preprocessing\n\n\n\n> **Ecrire votre texte ici.**","metadata":{"id":"3f45722f"}},{"cell_type":"code","source":"def preprocessing(inputs):\n\n    clean_inputs = inputs\n\n\n\n    # TO DO\n\n\n\n    return clean_inputs\n\n\n\nall_waves = np.ones((1, 1)) # à effacer\n\n\n\nprint(f'Input before preprocessing: {all_waves.shape}')\n\nprint(f'Input after preprocessing: {preprocessing(all_waves).shape}')","metadata":{"id":"c826fe03","outputId":"39bf9b28-c8ec-4ef1-b34e-5033fa39dbdf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Apprentissage du Modèle\n\nOn y est, il est temps de créer un modèle. Pour cela, il vous sera imposé d'utiliser un réseau de convolution 1D [2] (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D). Nous préconisons l'utilisation de Tensorflow mais vous êtes libre d'utiliser d'autres librairies comme Pytorch.\n\n\n\n&nbsp;\n\n\n\n<font color=\" Darkred\"> Progression du TP après cette partie (environ 3h): </font>  \n\n![75%](https://progress-bar.dev/75)","metadata":{"id":"d6640d2f"}},{"cell_type":"markdown","source":"### Train set, Validation set\n\n\n\nAvant d'entraîner votre modèle, pensez à séparer vos données d'entraînements et vos données de validations. Puis, pensez à créer des batchs pour correspondre à l'entrée de votre modèle.\n\n\n\nPlus d'infos ici:\n\n - https://www.tensorflow.org/datasets/splits?hl=fr\n\n - https://towardsdatascience.com/how-to-split-a-dataframe-into-train-and-test-set-with-python-eaa1630ca7b3\n\n - https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough?hl=fr\n\n\n\n <font color=\" Darkblue\"> **Tips:** Pensez à bien mélanger vos données avant de les séparer. </font>\n\n\n\n <font color=\"orange\"> **Note anti-plagiat:** Le mélange doit avoir une random seed fixe et différente pour chaque groupe. </font>","metadata":{"id":"adf9203f"}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\n\n\n\n\n\n# TO DO: Séparez vos données.\n\nX_train, y_train = np.random.rand(100, 1000), np.random.randint(0, high=12, size=100) # à effacer\n\nX_val, y_val = np.random.rand(100, 1000), np.random.randint(0, high=12, size=100) # à effacer\n\n\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=12)\n\ny_val = tf.keras.utils.to_categorical(y_val, num_classes=12)\n\n\n\nBATCH_SIZE = 32 #Vous pouvez le modifier\n\n\n\nX_train = np.expand_dims(X_train, axis=2)\n\ntrain = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n\ntrain = train.batch(32, drop_remainder=True)\n\n\n\nX_val = np.expand_dims(X_val, axis=2)\n\nval = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n\nval = val.batch(32, drop_remainder=True)\n\n\n\n\n\nfor example_inputs, example_labels in train.take(1):\n\n    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n\n    print(f'Labels shape (batch, time, features): {example_labels.shape}')","metadata":{"id":"13247892","outputId":"baf2c5cd-3bc5-4a70-f084-7917f687c3cc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Baseline\n\n\n\nLa baseline est importante afin de connaître le seuil où le modèle est performant. A vous de trouver la meilleure baseline et d'expliquer votre choix.\n\n\n\nPlus d'infos ici:\n\nhttps://towardsdatascience.com/calculating-a-baseline-accuracy-for-a-classification-model-a4b342ceb88f\n\n\n\n> **Ecrire votre texte ici.**","metadata":{"id":"34f099ea"}},{"cell_type":"code","source":"# TO DO\n\n\n\nresult_train, result_val = 0, 0 # à effacer\n\n\n\nprint(f'Train dataset: {result_train}%')\n\nprint(f'Validation dataset: {result_val}%')","metadata":{"id":"1b95413e","outputId":"1355e38d-8a5b-4b41-c054-79e8e832d8f9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Modèle\n\n\n\nVous devez créer une fonction permettant de générer le modèle. Celle-ci doit pouvoir être modifiable en fonction des Hyperparamètres mis en entrée.\n\n\n\n <font color=\"red\"> **ATTENTION:** Une limite de 150 000 paramètres est imposés. </font>\n\n\n\nJustification de vos choix (Choix des paramètres modifiables, fonction d'activations, nombres de couches, regularizers, ...) :\n\n> **Ecrire votre texte ici.**","metadata":{"id":"BRbcm3ibkYoM"}},{"cell_type":"code","source":"def total_param(model):\n\n# Ne pas modifier.\n\n  stringlist = []\n\n  model.summary(print_fn=lambda x: stringlist.append(x))\n\n  for line in stringlist[::-1]:\n\n    if \"Total params\" in line:\n\n      value = line.split('(')[1]\n\n      if value[-3:-1] == 'KB':\n\n        return float(value[:-4]) * 1e3\n\n      else:\n\n        return float(value[:-4]) * 1e6\n\n\n\n\n\ndef create_model(param):\n\n  # Exemple à modifier\n\n  model = tf.keras.Sequential()\n\n  model.add(tf.keras.layers.Conv1D(8, 100, strides=10, activation=param['activation'], input_shape=(1000,1)))\n\n  model.add(tf.keras.layers.Flatten())\n\n  for i in range(param['hidden_layer']):\n\n    model.add(tf.keras.layers.Dense(200, activation=param['activation']))\n\n  model.add(tf.keras.layers.Dense(12, activation='softmax'))\n\n  return model\n\n\n\nparam = {\n\n    # Exemple de paramètres à modifier\n\n    'activation' : 'relu',\n\n    'hidden_layer' : 1}\n\n\n\nmodel = create_model(param)\n\n\n\nmodel.summary()\n\nprint(f'Poids du modèle: {total_param(model)} octets')","metadata":{"id":"puz6cSOJmnCL","outputId":"322c9e57-f3b9-4c3b-c0f5-1c8533748ec9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fonction d'entraînement\n\n\n\nCette fonction doit prendre un modèle en entrée et l'entrainer grâce au Train set. Puis, retourner les performances obtenues avec le Validation set.\n\n\n\nPour les plus expérimentés d'entre vous: Vous pouvez réaliser une cross validation [[2]](https://datascientest.com/cross-validation).\n\n\n\nJustification de vos choix (Choix des paramètres modifiables, optimizer, nombres d'epoch, learning rate, ...) :\n\n> **Ecrire votre texte ici.**","metadata":{"id":"jdvfI-GGfSjJ"}},{"cell_type":"code","source":"def compile_and_fit(model, train, val, param, verbose=1):\n\n    # Exemple à modifier\n\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n\n                                                    patience=0.2,\n\n                                                    mode='min')\n\n\n\n    # Pour les plus confirmés\n\n    # lr = tf.optimizers.schedules.ExponentialDecay(\n\n    #     initial_learning_rate=1e-2,\n\n    #     decay_steps=1000,\n\n    #     decay_rate=0.95)\n\n\n\n    lr =  1e-3\n\n\n\n    model.compile(loss='categorical_crossentropy',\n\n                optimizer=tf.optimizers.Adam(learning_rate=lr),\n\n                metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')])\n\n\n\n    model.fit(train, epochs=param['max_epochs'],\n\n                      validation_data=val,\n\n                      callbacks=[early_stopping], verbose=verbose)\n\n\n\n    validation_accuracy = model.evaluate(val)\n\n    return validation_accuracy, model\n\n\n\nparam = {\n\n    # Exemple de paramètres à modifier\n\n    'max_epochs' : 1000\n\n}\n\n\n\nvalidation_accuracy = compile_and_fit(model, train, val, param)","metadata":{"id":"gxYxcPbOkdgu","outputId":"1ebdef7c-5f41-4f24-c861-d09e688a94c7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fit tuning des hyperparamètres.\n\n\n\nAprès avoir défini les hyperparamètres modifiables et vérifier que les fonctions fonctionnent, il est temps de lancer l'optimisation des hyperparamètres. Pour cela je vous invite à utiliser Optuna [[3]](https://optuna.readthedocs.io/en/stable/index.html) qui a plusieurs fonctionnalités:\n\n*   Une visualisation facilitée.\n\n*   Un suivi de l'avancement de l'optimisation.\n\n*   Une possibilité de reprendre l'optimisation sans reprendre depuis le début si un problème arrive durant le traitement.\n\n\n\n <font color=\" Darkblue\"> **Tips:** Essayez de lancer l'optimisation pendant le TP pour voir si il fonctionne et arretez le. Lancez le pour de bon à la fin de la séance ou pendant la semaine car cela va prendre plusieurs heures, voir plusieurs jours. </font>\n\n\n\n <font color=\"orange\"> **Note anti-plagiat:** L'optimisation doit avoir une random seed fixe et différente pour chaque groupe. </font>\n\n\n\n Merci de justifier vos plages de valeurs et faite un résumé sous forme de tableau :\n\n > **Ecrire votre texte ici.**\n\n\n\n\n\n | Hyperparamètre | Meilleure valeur | Plage | Step | Type de la plage |\n\n| :---------------- | :------: | :----: | :----: | :----: |\n\n| -   |  -  | - | - | - |","metadata":{"id":"Z0fbfyGPmACk"}},{"cell_type":"code","source":"!pip install optuna\n\n\n\nimport optuna\n\n\n\nSEED = 5\n\nnp.random.seed(SEED)\n\n\n\ndef objective(trial):\n\n\n\n    # Exemple de paramètres à modifier\n\n    param_model = {\n\n        'activation': trial.suggest_categorical(\"activation\", [\"relu\", \"selu\"]),\n\n        'hidden_layer' : trial.suggest_int('hidden_layer', 1, 3)\n\n    }\n\n\n\n    param_training = {\n\n        'max_epochs': trial.suggest_int('max_epochs', 800, 1000, step=100),\n\n    }\n\n\n\n    model = create_model(param_model)\n\n\n\n    metrics, _ = compile_and_fit(model, train, val, param_training, verbose=0)\n\n\n\n    trial.set_user_attr('Size', total_param(model))\n\n\n\n    return metrics[1]\n\n\n\n\n\nstudy_name = \"NOM1~NOM2-Tuning\"\n\nstorage_name = f'sqlite:////content/drive/MyDrive/TP N9EE39A/{study_name}.db' #Chemin à créer dans votre drive\n\n\n\nstudy = optuna.create_study(\n\n    direction='maximize',\n\n    study_name=study_name,\n\n    storage=storage_name,\n\n    sampler=optuna.samplers.TPESampler(seed=SEED),\n\n    load_if_exists=True)\n\n\n\nstudy.optimize(objective, n_trials=2)","metadata":{"id":"zcTnO30-fRc0","outputId":"a5606636-344d-418e-98fd-ee6633841a7f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Résultat et discussion\n\n\n\n<font color=\" Darkred\"> Progression du TP après cette partie (environ 3h): </font>  \n\n![84%](https://progress-bar.dev/84)\n","metadata":{"id":"Dbfa63od5fqW"}},{"cell_type":"markdown","source":"### Export du modèle\n\n\n\nMerci d'exporter le meilleur modèle et l'envoyer avec le jupyter notebook et la base de données d'entraînement. Lors de l'exportation d'un modèle, il est recommandé d'utiliser la base de donnée d'entrainement, et de validation.\n\n\n\n <font color=\"green\">*Cette partie du code est complète, vous n'avez pas besoin de la modifier.* </font>","metadata":{"id":"PpPA29teBDb8"}},{"cell_type":"code","source":"import joblib\n\n\n\nstudy = optuna.load_study(storage=storage_name, study_name=study_name)\n\nprint(\"Best trial until now:\")\n\nprint(\"   Value: \", study.best_trial.value)\n\nprint(\"   Params: \")\n\nfor key, value in study.best_trial.params.items():\n\n    print(f\"    -{key}: {value}\")\n\nprint(\"----------------------\")\n\n\n\nmodel = create_model(study.best_trial.params)\n\n\n\ntrain_and_val = tf.data.Dataset.from_tensor_slices((np.concatenate((X_train, X_val)), np.concatenate((y_train, y_val))))\n\ntrain_and_val = train_and_val.shuffle(1500, reshuffle_each_iteration=True)\n\ntrain_and_val = train_and_val.batch(32, drop_remainder=True)\n\n\n\n\n\n_, global_model = compile_and_fit(model, train_and_val, val, study.best_trial.params, verbose=0)\n\n\n\njoblib.dump(global_model, '/content/drive/MyDrive/TP N9EE39A/NOM1~NOM2_model.pkl')","metadata":{"id":"3bRjbe_O6E3t","outputId":"f149b691-2fcb-430b-c6d9-77b2021c1464"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dépôt sur Kaggle\n\n\n\nIl est temps de soumettre vos résultats sur Kaggle. Qu'en pensez vous, êtes vous satisfait de vos performances ? Est-ce que vous vous attendiez à ces performances ?\n\n\n\n <font color=\" Darkblue\"> **Tips:** Le format d'envoie et des tutoriels sont disponibles sur la page du concours. </font>\n\n\n\n <font color=\"orange\"> **Note anti-plagiat:** Il est impossible que le fichier que vous allez déposer soit le même qu'un autre binôme. Le fichier sera regénérer lors de la correction et doit être similaire avec celui déposé. </font>\n\n\n\nA la fin du projet, merci d'envoyer avec les autres fichiers ce fichier Kaggle avec comme nom **NOM1~NOM2_submission.csv**.\n\n\n\n> **Ecrire votre texte ici.**","metadata":{"id":"SHUXGNRoDl25"}},{"cell_type":"code","source":"#Ici, tous le code est à faire. Normalement, tous a déjà été codé ou est facilement trouvable sur internet et sur le site de la compétition !","metadata":{"id":"v9dSjfkUDAtH"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualisation des résultats\n\n\n\nIci tous le code a déjà été fait. Il faut par contre commenter les résultats et les performances que vous avez obtenu et l'utilité de chaque figure.","metadata":{"id":"YN7HC5eJHV-c"}},{"cell_type":"markdown","source":" #### Matrice de confusion\n\n\n\n <font color=\"green\">*Cette partie du code est complète, vous n'avez pas besoin de la modifier.* </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"rY-HrrAEIda-"}},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n\n\n\nstudy = optuna.load_study(storage=storage_name, study_name=study_name)\n\nmodel = create_model(study.best_trial.params)\n\n_, model = compile_and_fit(model, train, val, study.best_trial.params, verbose=0)\n\n\n\ny_prob= model.predict(val)\n\ny_pred = y_prob.argmax(axis=1)\n\n\n\nds_labels=[]\n\nfor images, labels in val.unbatch():\n\n    ds_labels.append(labels)\n\ny_ref = np.array(ds_labels).argmax(axis=1)\n\n\n\nlabel_names = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\", \"unknown\"]\n\nConfusionMatrixDisplay.from_predictions(y_ref, y_pred, cmap='Blues', normalize='true', ax=plt.subplots(figsize=(12,12))[1], display_labels=label_names)","metadata":{"id":"y4FcGZ2eIt4e","outputId":"2c9c7a31-aa69-4342-82a9-90ff8d4f3638"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Résultat du Fit-tuning\n\n\n\n <font color=\"green\">*Cette partie du code est complète, vous n'avez pas besoin de la modifier.* </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"CLLXGht5gaAq"}},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\n\noptuna.visualization.plot_optimization_history(study)","metadata":{"id":"ayaP_r7KhHLN","outputId":"479f1118-cd7f-4e84-8417-2631dd8a1655"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\n\noptuna.visualization.plot_slice(study)","metadata":{"id":"x87mlRGJjFJV","outputId":"2c007de8-18bf-4052-b04a-19212d313d9f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Influence des hyperparamètres sur les performances\n\n\n\n <font color=\"green\">*Cette partie du code est complète, vous n'avez pas besoin de la modifier.* </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"WKoCAyB4hYEb"}},{"cell_type":"code","source":"result = optuna.importance.get_param_importances(study)\n\nplt.figure(figsize=(12, 4.5), dpi=100)\n\nnames = list(result.keys())\n\nvalues = list(result.values())\n\n\n\nplt.bar(range(len(result)), np.array(values)*100, tick_label=names, color='#000233')\n\nplt.ylabel(\"Hyperparameter importance (%)\")\n\nplt.show()","metadata":{"id":"TwpQwAbVhh0V","outputId":"bab0e7e8-dc57-473e-dd81-7af948bce3a9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Influence des hyperparamètres sur le temps de calcul\n\n\n\n <font color=\"green\">*Cette partie du code est complète, vous n'avez pas besoin de la modifier.* </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"2taFMf4VhtWu"}},{"cell_type":"code","source":"result = optuna.importance.get_param_importances(study, target=lambda t: t.duration.total_seconds())\n\nplt.figure(figsize=(12, 4.5), dpi=100)\n\nnames = list(result.keys())\n\nvalues = list(result.values())\n\n\n\nplt.bar(range(len(result)), np.array(values)*100, tick_label=names, color='#000233')\n\nplt.ylabel(\"Hyperparameter importance (%)\")\n\nplt.show()","metadata":{"id":"_GwNNfu4h54x","outputId":"057257c7-1941-413f-bdc1-0986a7b363df"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Frontière de Pareto [[4]](https://fr.wikipedia.org/wiki/Optimum_de_Pareto)\n\n\n\n <font color=\"green\">*Cette partie du code est complète, vous n'avez pas besoin de la modifier.* </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"0zLsdT2gyfrq"}},{"cell_type":"code","source":"import pandas\n\n\n\ndef plot_pareto_frontier(Xs, Ys, maxX=True, maxY=True):\n\n  # From https://sirinnes.wordpress.com/2013/04/25/pareto-frontier-graphic-via-python/\n\n    '''Pareto frontier selection process'''\n\n    sorted_list = sorted([[Xs[i], Ys[i]] for i in range(len(Xs))], reverse=maxY)\n\n    pareto_front = [sorted_list[0]]\n\n    for pair in sorted_list[1:]:\n\n        if maxY:\n\n            if pair[1] >= pareto_front[-1][1]:\n\n                pareto_front.append(pair)\n\n        else:\n\n            if pair[1] <= pareto_front[-1][1]:\n\n                pareto_front.append(pair)\n\n\n\n    '''Plotting process'''\n\n    plt.scatter(Xs,Ys)\n\n    pf_X = [pair[0] for pair in pareto_front]\n\n    pf_Y = [pair[1] for pair in pareto_front]\n\n    plt.plot(pf_X, pf_Y)\n\n    plt.xlabel(\"Poids du modèle (octets)\")\n\n    plt.ylabel(\"Accuracy (%)\")\n\n    plt.show()\n\n\n\ndf = study.trials_dataframe()\n\nplot_pareto_frontier(df['user_attrs_Size'], df['value'])","metadata":{"id":"N9wEhDbWkdkN","outputId":"0c02b8a7-2a14-4711-ea96-17e0b3c85f97"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Allégement du modèle post-optimisation\n\n\n\nDans cette dernière partie, nous allons nous intéresser à l'influence des performances lorsque le modèle est allégé. Dans des appareils embarqués, il est nécessaire de trouver un compromis entre la performance du modèle, son poids, et la quantité d'opération.\n\n\n\nAu vue du nombre de séances, nous allons nous intéressé ici qu'au poids du système.\n\n\n\nPour cela, vous allez essayé de réduire le poids du meilleur modèle obtenu, puis avoir un regard critique sur les performances à chaque modification.\n\n\n\nVoici les techniques d'allégement à essayer:\n\n  - **La quantification**: Réduire le nombre d'octets des paramètres du modèles et les convertir en entiers [[5]](https://www.tensorflow.org/lite/performance/post_training_quantization).\n\n  - **L'élagage**: Supprimer les modèles qui ont un impact mineur sur les prédictions [[6]](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras).\n\n  - **Le clustering**: Regrouper les poids de chaque couche dans un modèle en un nombre prédéfini de clusters, puis en partageant les valeurs centroïdes pour les poids appartenant à chaque cluster individuel [[7]](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_example).\n\n  - **La décimation** : Réduire le nombre d'entrée.\n\n\n\n<font color=\" Darkred\"> Progression du TP après cette partie (environ 4h):\n\n\n\nEssayez d'avoir la meilleure accuracy avec un poids maximum inférieur à 75 KB.\n\n\n\n <font color=\" Darkblue\"> **Tips:**  Des tutoriels sont disponibles sur les liens attachés au techniques d'allégement. </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"pRqATIw30DB4"}},{"cell_type":"code","source":"#Ici, tous le code est à faire. Normalement, tous a déjà été codé ou est facilement trouvable sur internet !","metadata":{"id":"fCuo5Ug4436u"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### BONUS: Allégement avant optimisation\n\n\n\nRelancez un fit-tuning en rajoutant les paramètres d'allégements. Puis, observez les resultats avec une frontière de pareto. Les valeurs minimums de poids de la frontière doivent se trouver en dessous de 50 KB.\n\n\n\n <font color=\" Darkblue\"> **Tips:** Utilisez 2 métriques lorsque vous lancez la fonction d'activation. </font>\n\n\n\n > **Ecrire votre texte ici.**","metadata":{"id":"r-w4WkWa2pzl"}},{"cell_type":"code","source":"","metadata":{"id":"tw6JBclM3e1i"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\n\n\n\n\n <font color=\" Darkblue\"> **Tips:** Concluez sur vos résultats, les limitations de votre modèle et les perspectives envisagées pour l'améliorer. </font>\n\n\n\n\n\n <font color=\" Darkred\"> Progression du TP après cette partie (environ 0h30): </font>  \n\n\n\n\n\n> **Ecrire votre texte ici.**","metadata":{"id":"r3Qn7tP40xlT"}}]}